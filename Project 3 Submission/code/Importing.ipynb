{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90796ebe-31ae-4a1a-a69a-f6ea66e77c0e",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Web APIs & NLP  \n",
    "## PART 1/2: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeadb16-0528-4cf4-9c55-5d19c4ee21b2",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc562c4-0ec3-4503-af4a-e1ed94c45816",
   "metadata": {},
   "source": [
    "## 0. Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f6e155-a2ae-4daa-ab86-83269ce5e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c833209-917b-4204-b4fe-f04a0b67a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfb217d-aba4-4172-b5a3-07064dae2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \"subreddit\":\"zelda\",\n",
    "         \"size\":100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901e4c14-e8d8-4a8d-934b-0645b8dedac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19690466-2c7b-440d-8af8-a646b0234dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a399af-48d4-4df5-8435-ad08a4c8a25b",
   "metadata": {},
   "source": [
    "### 0.1 Identifying parameters to retrieve Subreddit posts by timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0fa46-8e9d-491c-8bab-c20a1754c8a0",
   "metadata": {},
   "source": [
    "I am targetting to retrieve at least 1,500 submissions per subreddit. As Pushshift can only retrieve up to 100 submissions per request, I need to submit multiple requests (15 requests per Subreddit) that collect data according to a designated timeframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37055b02-80de-4f5c-92d0-f4010f88e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earliest = 1658293974,latest = 1658159355\n"
     ]
    }
   ],
   "source": [
    "data = res.json()\n",
    "posts = data['data']\n",
    "\n",
    "first = posts[0]['created_utc']\n",
    "last = posts[-1]['created_utc']\n",
    "print(f\"earliest = {first},latest = {last}\")\n",
    "\n",
    "#we are looking for 'created_utc'\n",
    "#run through: https://www.epochconverter.com/\n",
    "#the other 499 posts are after this time\n",
    "\n",
    "# First = Tuesday, 19 July 2022 07:36:58\n",
    "# Last = Saturday, 16 July 2022 23:59:54\n",
    "\n",
    "#So, we want to setup the params as before the latest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912e8ca1-d50b-4bba-a796-d73ded1050fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef373a-f02a-4f0a-aefa-242f108a7bd7",
   "metadata": {},
   "source": [
    "### 0.2 Creating function(s) to retrieve and save multiple subreddits based on a pre-defined list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8989add2-542d-4805-b0c3-98b30d2786b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_creator(subreddit,count):\n",
    "    df_list = [f'df{i+1}' for i in range(count)]\n",
    "    df_files = [f'../dataset/{subreddit}/{df}.csv' for df in df_list]\n",
    "    list_creator.df_list = df_list\n",
    "    list_creator.df_files = df_files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6924bffc-7230-4fa3-ae65-d4bbd49cec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(subreddit,n):\n",
    "    df_files = [f'../dataset/{subreddit}/{df}.csv' for df in df_list]\n",
    "    res = requests.get(url,params)\n",
    "    data = res.json()\n",
    "    posts = data['data']\n",
    "    latest = posts[-1]['created_utc']\n",
    "    scraper.latest = latest\n",
    "    time.sleep(3)\n",
    "    globals()[df_list[n]] = pd.DataFrame(posts)\n",
    "    globals()[df_list[n]] = globals()[df_list[n]].loc[:,['subreddit','selftext','title']]\n",
    "    globals()[df_list[n]].to_csv(df_files[n],index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84ae36b-5dec-46cd-b21e-5b19249adca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_save(df_list):\n",
    "    for n,df in enumerate(df_list):\n",
    "        print(f\"{df} saved as {df_files[n]}\")\n",
    "        globals()[df] = pd.read_csv(df_files[n])\n",
    "    print(\"All individual files saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f6339-ae23-4836-99c8-3d5fb9128ba4",
   "metadata": {},
   "source": [
    "### 0.3 Function to combine individual outputs from each request into one consolidated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60da71ca-ca47-4afb-90ba-5d1e3052e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_combine(subreddit,df_list):\n",
    "    concat_list = [globals()[df] for df in df_list]\n",
    "    globals()[subreddit] = pd.concat(concat_list,ignore_index=True)\n",
    "    globals()[subreddit].to_csv(f\"../dataset/{subreddit}.csv\")\n",
    "    print(f\"{len(df_list)} files combined as '../dataset/{subreddit}.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c2724b-f0bc-4cc2-93bb-5ee341c61704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zelda\n",
      "---------\n",
      "{'subreddit': 'zelda', 'size': 100}\n",
      "number of files saved:1\n",
      "18-07-22\n",
      "number of files saved:2\n",
      "16-07-22\n",
      "number of files saved:3\n",
      "14-07-22\n",
      "number of files saved:4\n",
      "12-07-22\n",
      "number of files saved:5\n",
      "09-07-22\n",
      "number of files saved:6\n",
      "07-07-22\n",
      "number of files saved:7\n",
      "05-07-22\n",
      "number of files saved:8\n",
      "03-07-22\n",
      "number of files saved:9\n",
      "01-07-22\n",
      "number of files saved:10\n",
      "29-06-22\n",
      "number of files saved:11\n",
      "26-06-22\n",
      "number of files saved:12\n",
      "24-06-22\n",
      "number of files saved:13\n",
      "21-06-22\n",
      "number of files saved:14\n",
      "18-06-22\n",
      "df1 saved as ../dataset/zelda/df1.csv\n",
      "df2 saved as ../dataset/zelda/df2.csv\n",
      "df3 saved as ../dataset/zelda/df3.csv\n",
      "df4 saved as ../dataset/zelda/df4.csv\n",
      "df5 saved as ../dataset/zelda/df5.csv\n",
      "df6 saved as ../dataset/zelda/df6.csv\n",
      "df7 saved as ../dataset/zelda/df7.csv\n",
      "df8 saved as ../dataset/zelda/df8.csv\n",
      "df9 saved as ../dataset/zelda/df9.csv\n",
      "df10 saved as ../dataset/zelda/df10.csv\n",
      "df11 saved as ../dataset/zelda/df11.csv\n",
      "df12 saved as ../dataset/zelda/df12.csv\n",
      "df13 saved as ../dataset/zelda/df13.csv\n",
      "df14 saved as ../dataset/zelda/df14.csv\n",
      "df15 saved as ../dataset/zelda/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/zelda.csv'\n",
      "adidas\n",
      "---------\n",
      "{'subreddit': 'adidas', 'size': 100}\n",
      "number of files saved:1\n",
      "14-07-22\n",
      "number of files saved:2\n",
      "07-07-22\n",
      "number of files saved:3\n",
      "30-06-22\n",
      "number of files saved:4\n",
      "23-06-22\n",
      "number of files saved:5\n",
      "16-06-22\n",
      "number of files saved:6\n",
      "09-06-22\n",
      "number of files saved:7\n",
      "02-06-22\n",
      "number of files saved:8\n",
      "25-05-22\n",
      "number of files saved:9\n",
      "18-05-22\n",
      "number of files saved:10\n",
      "11-05-22\n",
      "number of files saved:11\n",
      "05-05-22\n",
      "number of files saved:12\n",
      "29-04-22\n",
      "number of files saved:13\n",
      "23-04-22\n",
      "number of files saved:14\n",
      "17-04-22\n",
      "df1 saved as ../dataset/adidas/df1.csv\n",
      "df2 saved as ../dataset/adidas/df2.csv\n",
      "df3 saved as ../dataset/adidas/df3.csv\n",
      "df4 saved as ../dataset/adidas/df4.csv\n",
      "df5 saved as ../dataset/adidas/df5.csv\n",
      "df6 saved as ../dataset/adidas/df6.csv\n",
      "df7 saved as ../dataset/adidas/df7.csv\n",
      "df8 saved as ../dataset/adidas/df8.csv\n",
      "df9 saved as ../dataset/adidas/df9.csv\n",
      "df10 saved as ../dataset/adidas/df10.csv\n",
      "df11 saved as ../dataset/adidas/df11.csv\n",
      "df12 saved as ../dataset/adidas/df12.csv\n",
      "df13 saved as ../dataset/adidas/df13.csv\n",
      "df14 saved as ../dataset/adidas/df14.csv\n",
      "df15 saved as ../dataset/adidas/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/adidas.csv'\n",
      "Nike\n",
      "---------\n",
      "{'subreddit': 'Nike', 'size': 100}\n",
      "number of files saved:1\n",
      "18-07-22\n",
      "number of files saved:2\n",
      "15-07-22\n",
      "number of files saved:3\n",
      "12-07-22\n",
      "number of files saved:4\n",
      "09-07-22\n",
      "number of files saved:5\n",
      "06-07-22\n",
      "number of files saved:6\n",
      "03-07-22\n",
      "number of files saved:7\n",
      "30-06-22\n",
      "number of files saved:8\n",
      "27-06-22\n",
      "number of files saved:9\n",
      "24-06-22\n",
      "number of files saved:10\n",
      "21-06-22\n",
      "number of files saved:11\n",
      "18-06-22\n",
      "number of files saved:12\n",
      "16-06-22\n",
      "number of files saved:13\n",
      "13-06-22\n",
      "number of files saved:14\n",
      "10-06-22\n",
      "df1 saved as ../dataset/Nike/df1.csv\n",
      "df2 saved as ../dataset/Nike/df2.csv\n",
      "df3 saved as ../dataset/Nike/df3.csv\n",
      "df4 saved as ../dataset/Nike/df4.csv\n",
      "df5 saved as ../dataset/Nike/df5.csv\n",
      "df6 saved as ../dataset/Nike/df6.csv\n",
      "df7 saved as ../dataset/Nike/df7.csv\n",
      "df8 saved as ../dataset/Nike/df8.csv\n",
      "df9 saved as ../dataset/Nike/df9.csv\n",
      "df10 saved as ../dataset/Nike/df10.csv\n",
      "df11 saved as ../dataset/Nike/df11.csv\n",
      "df12 saved as ../dataset/Nike/df12.csv\n",
      "df13 saved as ../dataset/Nike/df13.csv\n",
      "df14 saved as ../dataset/Nike/df14.csv\n",
      "df15 saved as ../dataset/Nike/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/Nike.csv'\n",
      "wiiu\n",
      "---------\n",
      "{'subreddit': 'wiiu', 'size': 100}\n",
      "number of files saved:1\n",
      "15-07-22\n",
      "number of files saved:2\n",
      "09-07-22\n",
      "number of files saved:3\n",
      "02-07-22\n",
      "number of files saved:4\n",
      "24-06-22\n",
      "number of files saved:5\n",
      "17-06-22\n",
      "number of files saved:6\n",
      "11-06-22\n",
      "number of files saved:7\n",
      "02-06-22\n",
      "number of files saved:8\n",
      "26-05-22\n",
      "number of files saved:9\n",
      "19-05-22\n",
      "number of files saved:10\n",
      "13-05-22\n",
      "number of files saved:11\n",
      "07-05-22\n",
      "number of files saved:12\n",
      "29-04-22\n",
      "number of files saved:13\n",
      "23-04-22\n",
      "number of files saved:14\n",
      "15-04-22\n",
      "df1 saved as ../dataset/wiiu/df1.csv\n",
      "df2 saved as ../dataset/wiiu/df2.csv\n",
      "df3 saved as ../dataset/wiiu/df3.csv\n",
      "df4 saved as ../dataset/wiiu/df4.csv\n",
      "df5 saved as ../dataset/wiiu/df5.csv\n",
      "df6 saved as ../dataset/wiiu/df6.csv\n",
      "df7 saved as ../dataset/wiiu/df7.csv\n",
      "df8 saved as ../dataset/wiiu/df8.csv\n",
      "df9 saved as ../dataset/wiiu/df9.csv\n",
      "df10 saved as ../dataset/wiiu/df10.csv\n",
      "df11 saved as ../dataset/wiiu/df11.csv\n",
      "df12 saved as ../dataset/wiiu/df12.csv\n",
      "df13 saved as ../dataset/wiiu/df13.csv\n",
      "df14 saved as ../dataset/wiiu/df14.csv\n",
      "df15 saved as ../dataset/wiiu/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/wiiu.csv'\n",
      "crocs\n",
      "---------\n",
      "{'subreddit': 'crocs', 'size': 100}\n",
      "number of files saved:1\n",
      "14-07-22\n",
      "number of files saved:2\n",
      "08-07-22\n",
      "number of files saved:3\n",
      "01-07-22\n",
      "number of files saved:4\n",
      "25-06-22\n",
      "number of files saved:5\n",
      "17-06-22\n",
      "number of files saved:6\n",
      "10-06-22\n",
      "number of files saved:7\n",
      "02-06-22\n",
      "number of files saved:8\n",
      "21-05-22\n",
      "number of files saved:9\n",
      "09-05-22\n",
      "number of files saved:10\n",
      "28-04-22\n",
      "number of files saved:11\n",
      "12-04-22\n",
      "number of files saved:12\n",
      "23-03-22\n",
      "number of files saved:13\n",
      "02-03-22\n",
      "number of files saved:14\n",
      "07-02-22\n",
      "df1 saved as ../dataset/crocs/df1.csv\n",
      "df2 saved as ../dataset/crocs/df2.csv\n",
      "df3 saved as ../dataset/crocs/df3.csv\n",
      "df4 saved as ../dataset/crocs/df4.csv\n",
      "df5 saved as ../dataset/crocs/df5.csv\n",
      "df6 saved as ../dataset/crocs/df6.csv\n",
      "df7 saved as ../dataset/crocs/df7.csv\n",
      "df8 saved as ../dataset/crocs/df8.csv\n",
      "df9 saved as ../dataset/crocs/df9.csv\n",
      "df10 saved as ../dataset/crocs/df10.csv\n",
      "df11 saved as ../dataset/crocs/df11.csv\n",
      "df12 saved as ../dataset/crocs/df12.csv\n",
      "df13 saved as ../dataset/crocs/df13.csv\n",
      "df14 saved as ../dataset/crocs/df14.csv\n",
      "df15 saved as ../dataset/crocs/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/crocs.csv'\n",
      "StardewValley\n",
      "---------\n",
      "{'subreddit': 'StardewValley', 'size': 100}\n",
      "number of files saved:1\n",
      "20-07-22\n",
      "number of files saved:2\n",
      "19-07-22\n",
      "number of files saved:3\n",
      "19-07-22\n",
      "number of files saved:4\n",
      "19-07-22\n",
      "number of files saved:5\n",
      "18-07-22\n",
      "number of files saved:6\n",
      "18-07-22\n",
      "number of files saved:7\n",
      "18-07-22\n",
      "number of files saved:8\n",
      "17-07-22\n",
      "number of files saved:9\n",
      "17-07-22\n",
      "number of files saved:10\n",
      "16-07-22\n",
      "number of files saved:11\n",
      "16-07-22\n",
      "number of files saved:12\n",
      "15-07-22\n",
      "number of files saved:13\n",
      "15-07-22\n",
      "number of files saved:14\n",
      "15-07-22\n",
      "df1 saved as ../dataset/StardewValley/df1.csv\n",
      "df2 saved as ../dataset/StardewValley/df2.csv\n",
      "df3 saved as ../dataset/StardewValley/df3.csv\n",
      "df4 saved as ../dataset/StardewValley/df4.csv\n",
      "df5 saved as ../dataset/StardewValley/df5.csv\n",
      "df6 saved as ../dataset/StardewValley/df6.csv\n",
      "df7 saved as ../dataset/StardewValley/df7.csv\n",
      "df8 saved as ../dataset/StardewValley/df8.csv\n",
      "df9 saved as ../dataset/StardewValley/df9.csv\n",
      "df10 saved as ../dataset/StardewValley/df10.csv\n",
      "df11 saved as ../dataset/StardewValley/df11.csv\n",
      "df12 saved as ../dataset/StardewValley/df12.csv\n",
      "df13 saved as ../dataset/StardewValley/df13.csv\n",
      "df14 saved as ../dataset/StardewValley/df14.csv\n",
      "df15 saved as ../dataset/StardewValley/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/StardewValley.csv'\n",
      "harvestmoon\n",
      "---------\n",
      "{'subreddit': 'harvestmoon', 'size': 100}\n",
      "number of files saved:1\n",
      "10-07-22\n",
      "number of files saved:2\n",
      "26-06-22\n",
      "number of files saved:3\n",
      "08-06-22\n",
      "number of files saved:4\n",
      "23-05-22\n",
      "number of files saved:5\n",
      "05-05-22\n",
      "number of files saved:6\n",
      "16-04-22\n",
      "number of files saved:7\n",
      "27-03-22\n",
      "number of files saved:8\n",
      "10-03-22\n",
      "number of files saved:9\n",
      "19-02-22\n",
      "number of files saved:10\n",
      "24-01-22\n",
      "number of files saved:11\n",
      "06-01-22\n",
      "number of files saved:12\n",
      "12-12-21\n",
      "number of files saved:13\n",
      "21-11-21\n",
      "number of files saved:14\n",
      "04-11-21\n",
      "df1 saved as ../dataset/harvestmoon/df1.csv\n",
      "df2 saved as ../dataset/harvestmoon/df2.csv\n",
      "df3 saved as ../dataset/harvestmoon/df3.csv\n",
      "df4 saved as ../dataset/harvestmoon/df4.csv\n",
      "df5 saved as ../dataset/harvestmoon/df5.csv\n",
      "df6 saved as ../dataset/harvestmoon/df6.csv\n",
      "df7 saved as ../dataset/harvestmoon/df7.csv\n",
      "df8 saved as ../dataset/harvestmoon/df8.csv\n",
      "df9 saved as ../dataset/harvestmoon/df9.csv\n",
      "df10 saved as ../dataset/harvestmoon/df10.csv\n",
      "df11 saved as ../dataset/harvestmoon/df11.csv\n",
      "df12 saved as ../dataset/harvestmoon/df12.csv\n",
      "df13 saved as ../dataset/harvestmoon/df13.csv\n",
      "df14 saved as ../dataset/harvestmoon/df14.csv\n",
      "df15 saved as ../dataset/harvestmoon/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/harvestmoon.csv'\n",
      "NintendoSwitch\n",
      "---------\n",
      "{'subreddit': 'NintendoSwitch', 'size': 100}\n",
      "number of files saved:1\n",
      "19-07-22\n",
      "number of files saved:2\n",
      "19-07-22\n",
      "number of files saved:3\n",
      "18-07-22\n",
      "number of files saved:4\n",
      "17-07-22\n",
      "number of files saved:5\n",
      "16-07-22\n",
      "number of files saved:6\n",
      "16-07-22\n",
      "number of files saved:7\n",
      "15-07-22\n",
      "number of files saved:8\n",
      "14-07-22\n",
      "number of files saved:9\n",
      "13-07-22\n",
      "number of files saved:10\n",
      "13-07-22\n",
      "number of files saved:11\n",
      "12-07-22\n",
      "number of files saved:12\n",
      "11-07-22\n",
      "number of files saved:13\n",
      "10-07-22\n",
      "number of files saved:14\n",
      "10-07-22\n",
      "df1 saved as ../dataset/NintendoSwitch/df1.csv\n",
      "df2 saved as ../dataset/NintendoSwitch/df2.csv\n",
      "df3 saved as ../dataset/NintendoSwitch/df3.csv\n",
      "df4 saved as ../dataset/NintendoSwitch/df4.csv\n",
      "df5 saved as ../dataset/NintendoSwitch/df5.csv\n",
      "df6 saved as ../dataset/NintendoSwitch/df6.csv\n",
      "df7 saved as ../dataset/NintendoSwitch/df7.csv\n",
      "df8 saved as ../dataset/NintendoSwitch/df8.csv\n",
      "df9 saved as ../dataset/NintendoSwitch/df9.csv\n",
      "df10 saved as ../dataset/NintendoSwitch/df10.csv\n",
      "df11 saved as ../dataset/NintendoSwitch/df11.csv\n",
      "df12 saved as ../dataset/NintendoSwitch/df12.csv\n",
      "df13 saved as ../dataset/NintendoSwitch/df13.csv\n",
      "df14 saved as ../dataset/NintendoSwitch/df14.csv\n",
      "df15 saved as ../dataset/NintendoSwitch/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/NintendoSwitch.csv'\n"
     ]
    }
   ],
   "source": [
    "subr_list = [\"zelda\",\"adidas\",\"Nike\",\"wiiu\",\"crocs\",\"StardewValley\",\"harvestmoon\",\"NintendoSwitch\"]\n",
    "params = { \"subreddit\":\"zelda\",\n",
    "         \"size\":100,\"before\":0}\n",
    "\n",
    "for subreddit in subr_list:\n",
    "    print(subreddit)\n",
    "    print(\"---------\")\n",
    "    params[\"subreddit\"] = subreddit\n",
    "    del params[\"before\"]\n",
    "    print(params)\n",
    "    \n",
    "    res = requests.get(url,params)\n",
    "    data = res.json()\n",
    "    posts = data['data']\n",
    "    \n",
    "    list_creator(subreddit,15)\n",
    "\n",
    "    df_list = list_creator.df_list\n",
    "    df_files = list_creator.df_files \n",
    "\n",
    "    scraper(subreddit,0)\n",
    "\n",
    "    for n in range(len(df_list)-1):\n",
    "        params[\"before\"] = scraper.latest\n",
    "        x = n+1\n",
    "        print(f\"number of files saved:{x}\")\n",
    "        print(datetime.fromtimestamp(scraper.latest).strftime('%d-%m-%y'))\n",
    "        scraper(subreddit,x)\n",
    "\n",
    "    file_save(df_list)\n",
    "\n",
    "    file_combine(subreddit,df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2db44ae0-de69-4f41-984b-27ebe9ecbde3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keto\n",
      "---------\n",
      "{'subreddit': 'keto', 'size': 100}\n",
      "number of files saved:1\n",
      "19-07-22\n",
      "number of files saved:2\n",
      "17-07-22\n",
      "number of files saved:3\n",
      "15-07-22\n",
      "number of files saved:4\n",
      "14-07-22\n",
      "number of files saved:5\n",
      "11-07-22\n",
      "number of files saved:6\n",
      "09-07-22\n",
      "number of files saved:7\n",
      "07-07-22\n",
      "number of files saved:8\n",
      "05-07-22\n",
      "number of files saved:9\n",
      "03-07-22\n",
      "number of files saved:10\n",
      "01-07-22\n",
      "number of files saved:11\n",
      "29-06-22\n",
      "number of files saved:12\n",
      "27-06-22\n",
      "number of files saved:13\n",
      "24-06-22\n",
      "number of files saved:14\n",
      "23-06-22\n",
      "df1 saved as ../dataset/keto/df1.csv\n",
      "df2 saved as ../dataset/keto/df2.csv\n",
      "df3 saved as ../dataset/keto/df3.csv\n",
      "df4 saved as ../dataset/keto/df4.csv\n",
      "df5 saved as ../dataset/keto/df5.csv\n",
      "df6 saved as ../dataset/keto/df6.csv\n",
      "df7 saved as ../dataset/keto/df7.csv\n",
      "df8 saved as ../dataset/keto/df8.csv\n",
      "df9 saved as ../dataset/keto/df9.csv\n",
      "df10 saved as ../dataset/keto/df10.csv\n",
      "df11 saved as ../dataset/keto/df11.csv\n",
      "df12 saved as ../dataset/keto/df12.csv\n",
      "df13 saved as ../dataset/keto/df13.csv\n",
      "df14 saved as ../dataset/keto/df14.csv\n",
      "df15 saved as ../dataset/keto/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/keto.csv'\n",
      "Paleo\n",
      "---------\n",
      "{'subreddit': 'Paleo', 'size': 100}\n",
      "number of files saved:1\n",
      "03-06-22\n",
      "number of files saved:2\n",
      "27-04-22\n",
      "number of files saved:3\n",
      "16-03-22\n",
      "number of files saved:4\n",
      "11-02-22\n",
      "number of files saved:5\n",
      "31-12-21\n",
      "number of files saved:6\n",
      "11-11-21\n",
      "number of files saved:7\n",
      "27-09-21\n",
      "number of files saved:8\n",
      "27-08-21\n",
      "number of files saved:9\n",
      "31-07-21\n",
      "number of files saved:10\n",
      "07-07-21\n",
      "number of files saved:11\n",
      "14-06-21\n",
      "number of files saved:12\n",
      "16-05-21\n",
      "number of files saved:13\n",
      "22-04-21\n",
      "number of files saved:14\n",
      "17-03-21\n",
      "df1 saved as ../dataset/Paleo/df1.csv\n",
      "df2 saved as ../dataset/Paleo/df2.csv\n",
      "df3 saved as ../dataset/Paleo/df3.csv\n",
      "df4 saved as ../dataset/Paleo/df4.csv\n",
      "df5 saved as ../dataset/Paleo/df5.csv\n",
      "df6 saved as ../dataset/Paleo/df6.csv\n",
      "df7 saved as ../dataset/Paleo/df7.csv\n",
      "df8 saved as ../dataset/Paleo/df8.csv\n",
      "df9 saved as ../dataset/Paleo/df9.csv\n",
      "df10 saved as ../dataset/Paleo/df10.csv\n",
      "df11 saved as ../dataset/Paleo/df11.csv\n",
      "df12 saved as ../dataset/Paleo/df12.csv\n",
      "df13 saved as ../dataset/Paleo/df13.csv\n",
      "df14 saved as ../dataset/Paleo/df14.csv\n",
      "df15 saved as ../dataset/Paleo/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/Paleo.csv'\n",
      "Chiropractic\n",
      "---------\n",
      "{'subreddit': 'Chiropractic', 'size': 100}\n",
      "number of files saved:1\n",
      "07-07-22\n",
      "number of files saved:2\n",
      "20-06-22\n",
      "number of files saved:3\n",
      "08-06-22\n",
      "number of files saved:4\n",
      "26-05-22\n",
      "number of files saved:5\n",
      "13-05-22\n",
      "number of files saved:6\n",
      "29-04-22\n",
      "number of files saved:7\n",
      "15-04-22\n",
      "number of files saved:8\n",
      "01-04-22\n",
      "number of files saved:9\n",
      "18-03-22\n",
      "number of files saved:10\n",
      "05-03-22\n",
      "number of files saved:11\n",
      "19-02-22\n",
      "number of files saved:12\n",
      "05-02-22\n",
      "number of files saved:13\n",
      "20-01-22\n",
      "number of files saved:14\n",
      "06-01-22\n",
      "df1 saved as ../dataset/Chiropractic/df1.csv\n",
      "df2 saved as ../dataset/Chiropractic/df2.csv\n",
      "df3 saved as ../dataset/Chiropractic/df3.csv\n",
      "df4 saved as ../dataset/Chiropractic/df4.csv\n",
      "df5 saved as ../dataset/Chiropractic/df5.csv\n",
      "df6 saved as ../dataset/Chiropractic/df6.csv\n",
      "df7 saved as ../dataset/Chiropractic/df7.csv\n",
      "df8 saved as ../dataset/Chiropractic/df8.csv\n",
      "df9 saved as ../dataset/Chiropractic/df9.csv\n",
      "df10 saved as ../dataset/Chiropractic/df10.csv\n",
      "df11 saved as ../dataset/Chiropractic/df11.csv\n",
      "df12 saved as ../dataset/Chiropractic/df12.csv\n",
      "df13 saved as ../dataset/Chiropractic/df13.csv\n",
      "df14 saved as ../dataset/Chiropractic/df14.csv\n",
      "df15 saved as ../dataset/Chiropractic/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/Chiropractic.csv'\n",
      "physiotherapy\n",
      "---------\n",
      "{'subreddit': 'physiotherapy', 'size': 100}\n",
      "number of files saved:1\n",
      "26-06-22\n",
      "number of files saved:2\n",
      "27-05-22\n",
      "number of files saved:3\n",
      "01-05-22\n",
      "number of files saved:4\n",
      "01-04-22\n",
      "number of files saved:5\n",
      "05-03-22\n",
      "number of files saved:6\n",
      "05-02-22\n",
      "number of files saved:7\n",
      "08-01-22\n",
      "number of files saved:8\n",
      "03-12-21\n",
      "number of files saved:9\n",
      "06-11-21\n",
      "number of files saved:10\n",
      "04-10-21\n",
      "number of files saved:11\n",
      "08-09-21\n",
      "number of files saved:12\n",
      "12-08-21\n",
      "number of files saved:13\n",
      "14-07-21\n",
      "number of files saved:14\n",
      "07-06-21\n",
      "df1 saved as ../dataset/physiotherapy/df1.csv\n",
      "df2 saved as ../dataset/physiotherapy/df2.csv\n",
      "df3 saved as ../dataset/physiotherapy/df3.csv\n",
      "df4 saved as ../dataset/physiotherapy/df4.csv\n",
      "df5 saved as ../dataset/physiotherapy/df5.csv\n",
      "df6 saved as ../dataset/physiotherapy/df6.csv\n",
      "df7 saved as ../dataset/physiotherapy/df7.csv\n",
      "df8 saved as ../dataset/physiotherapy/df8.csv\n",
      "df9 saved as ../dataset/physiotherapy/df9.csv\n",
      "df10 saved as ../dataset/physiotherapy/df10.csv\n",
      "df11 saved as ../dataset/physiotherapy/df11.csv\n",
      "df12 saved as ../dataset/physiotherapy/df12.csv\n",
      "df13 saved as ../dataset/physiotherapy/df13.csv\n",
      "df14 saved as ../dataset/physiotherapy/df14.csv\n",
      "df15 saved as ../dataset/physiotherapy/df15.csv\n",
      "All individual files saved\n",
      "15 files combined as '../dataset/physiotherapy.csv'\n"
     ]
    }
   ],
   "source": [
    "subr_list = [\"keto\",\"Paleo\",\"Chiropractic\",\"physiotherapy\"]\n",
    "params = { \"subreddit\":\"zelda\",\n",
    "         \"size\":100,\"before\":0}\n",
    "\n",
    "for subreddit in subr_list:\n",
    "    print(subreddit)\n",
    "    print(\"---------\")\n",
    "    params[\"subreddit\"] = subreddit\n",
    "    del params[\"before\"]\n",
    "    print(params)\n",
    "    \n",
    "    res = requests.get(url,params)\n",
    "    data = res.json()\n",
    "    posts = data['data']\n",
    "    \n",
    "    list_creator(subreddit,15)\n",
    "\n",
    "    df_list = list_creator.df_list\n",
    "    df_files = list_creator.df_files \n",
    "\n",
    "    scraper(subreddit,0)\n",
    "\n",
    "    for n in range(len(df_list)-1):\n",
    "        params[\"before\"] = scraper.latest\n",
    "        x = n+1\n",
    "        print(f\"number of files saved:{x}\")\n",
    "        print(datetime.fromtimestamp(scraper.latest).strftime('%d-%m-%y'))\n",
    "        scraper(subreddit,x)\n",
    "\n",
    "    file_save(df_list)\n",
    "\n",
    "    file_combine(subreddit,df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf9678-8e20-4285-8eeb-58cbb0d2ca56",
   "metadata": {},
   "source": [
    "### 0.4 Preliminary Analysis of Retrieved Subreddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c81927-fd5d-4e49-91ec-e836fa07f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(subreddit):\n",
    "    x = globals()[subreddit]\n",
    "    x = pd.read_csv(f\"../dataset/{subreddit}.csv\",index_col = [0])\n",
    "    print(subreddit)\n",
    "    print(\"-----\")\n",
    "    print(x.shape)\n",
    "    print(x.isnull().sum())\n",
    "    globals()[subreddit] = x\n",
    "    return globals()[subreddit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d2db769-ed7c-4da6-8f35-79f9f8c9c673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zelda\n",
      "-----\n",
      "(1499, 3)\n",
      "subreddit       0\n",
      "selftext     1020\n",
      "title           0\n",
      "dtype: int64\n",
      "adidas\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit       0\n",
      "selftext     1085\n",
      "title           0\n",
      "dtype: int64\n",
      "Nike\n",
      "-----\n",
      "(1498, 3)\n",
      "subreddit       0\n",
      "selftext     1133\n",
      "title           0\n",
      "dtype: int64\n",
      "wiiu\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit      0\n",
      "selftext     584\n",
      "title          0\n",
      "dtype: int64\n",
      "crocs\n",
      "-----\n",
      "(1499, 3)\n",
      "subreddit       0\n",
      "selftext     1075\n",
      "title           0\n",
      "dtype: int64\n",
      "StardewValley\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit      0\n",
      "selftext     836\n",
      "title          0\n",
      "dtype: int64\n",
      "harvestmoon\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit      0\n",
      "selftext     699\n",
      "title          0\n",
      "dtype: int64\n",
      "NintendoSwitch\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit      0\n",
      "selftext     415\n",
      "title          0\n",
      "dtype: int64\n",
      "keto\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit    0\n",
      "selftext     8\n",
      "title        0\n",
      "dtype: int64\n",
      "Paleo\n",
      "-----\n",
      "(1498, 3)\n",
      "subreddit      0\n",
      "selftext     623\n",
      "title          0\n",
      "dtype: int64\n",
      "Chiropractic\n",
      "-----\n",
      "(1500, 3)\n",
      "subreddit      0\n",
      "selftext     484\n",
      "title          0\n",
      "dtype: int64\n",
      "physiotherapy\n",
      "-----\n",
      "(1499, 3)\n",
      "subreddit      0\n",
      "selftext     228\n",
      "title          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "consol_df_list = [reader(subreddit) for subreddit in [\"zelda\",\"adidas\",\"Nike\",\"wiiu\",\"crocs\",\"StardewValley\",\"harvestmoon\",\"NintendoSwitch\",\"keto\",\"Paleo\",\"Chiropractic\",\"physiotherapy\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d11c6-f385-4cdd-9715-35e262789293",
   "metadata": {},
   "source": [
    "## Data Selection Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f734fd-bce5-4fc4-8c88-b5c484ae5363",
   "metadata": {},
   "source": [
    "1. Using Pushshift's API, I collected submissions from multiple subreddits, focusing on the \"title\" and \"selftext\" fields.\n",
    "   - I excluded posts/comments for this scraping exercise. This is intended to reduce unnecessary noise as comments can often times veer off-topic. \n",
    "2. Criteria for selection:\n",
    "   - At least 1500 observations per subreddit, to ensure there is sufficient data left after cleaning (ie: at least 1000 observations per subreddit post-cleaning)\n",
    "   - Minimal null values in the fields retrieved. Target is to have less than 500 null cells in *each* chosen subreddit. \n",
    "   - Submissions in the subreddit must be more text-heavy rather than image-heavy, such that there is sufficient text data left for NLP. That rules out subreddits with plenty of images such as food photos, shoes, memes, in-game screenshots, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4d653-2350-49a7-9cfd-5235a1fb70ed",
   "metadata": {},
   "source": [
    "Based on the above criteria, I have shortlisted the **\"Physiotherapy\"** and **\"Chiropractic\"** subreddits as the focus of this Project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
